

What are kAuto,kDynamic,kStatic,kGuided for? 
How is the Dmat constructed, are the trees stored here?
How is the random forest turned into datamatrices? 

Idea(s):
- function for extracting depth from trees
- a way to control which trees get placed into which batches (not arbitrary assignment)
- function to sort trees based on depth

[t1,t2,t3,...,tn] d(t1) <= d(tn)
[3,3,4,5,7,8,10,15,20,23,23,25,25,30] : 14

[small,med,large]
Assume a prediction for a tree with 1 node is 1 second
[[3,3,4,5,7], [8,10,15,20], [23,23,25,25,30]]

Batch set 1:
[23,23,25,25,30] = 126
[8,10,15,20] = 53
[3,3,4,5,7] = 22

Batch set 2:
[30,8,3] = 41
[25,10,3] = 38
[25,15,4] = 44
[23,20,5] = 48
[23,7] = 30

=> Batch set 1 will take 126 seconds and Batc set 2 will take 48
=> SAT solver
=> minimize the prediction times for all batches => minimize largest prediction time for a single batch 

- function to generate optimal batch arrangement
	- compute number of threads needed
	- #threads ~ #large trees

[1,1,2,2,3,20,25,41]
mean = 11.8 => large = anything >= 12
=> 3 threads
[41] = 41
[25,1,3] = 29
[20,2,1,2] = 25


[3,3,4,5,7,8,10,15,20,23,23,25,25,30] : 14
# threads = 7

	3 3 4 5 7 8 10
30  0 0 0 0 0 0 0
25  0 0 0 0 0 0 0
25  0 0 0 0 0 0 0
23  0 0 0 0 0 0 0
23  0 0 0 0 0 0 0
20  0 0 0 0 0 0 0
15  0 0 0 0 0 0 0




Experiment:

XGBoost, trains a model -> save as json_config -> distributes json_config -> load model using json_config -> make prediction. (overhead?)
train -> compile to native binary/common-spec -> distribute -> make prediction. (less overhead?)


Paper 1: Fast Gradien Boosted Decision Tree for Multioutput problems

- Accelerated training process of GBDT when the outputs are multidimensional (multiclass/multilabel classification, multioutput regression)
- Develop a scoring function to find the best split of decision tree
- Scoring function implemented in SketchBoost
- DT's are useful methods for solving prediction problems in both classification and regression  domains.
- Dominant tool in applications where tabular data is abundant  (e-commerce, financial and retail industries)

Paper 2: CudaRF: A CUDA-based Implementation of Random Forests

- GPU-based parallel implementation of Random Forests
- GPGPU: General purpose computing on graphics processing units
- Difficult to optimize DT-based problems for GPU-based execution
- Both the training phase and classification phase are parrallelized in CUDA implementation
- CUDA: Compute Unified Device Architecture is an API extension to C and contains specific ISA for access to the parallel compute engine in the GPU





(Link target) ->
  c_api.obj : error LNK2019: unresolved external symbol "public: static class std::unique_ptr<class tl2cgen::DenseDMatrix,struct std::default_delete<class tl2cgen::DenseDMatrix> > __cdecl tl2cgen::DenseDMatrix::Create(en
um tl2cgen::predictor::DataTypeEnum,void const *,void const *,unsigned __int64,unsigned __int64)" (?Create@DenseDMatrix@tl2cgen@@SA?AV?$unique_ptr@VDenseDMatrix@tl2cgen@@U?$default_delete@VDenseDMatrix@tl2cgen@@@std@@@st
d@@W4DataTypeEnum@predictor@2@PEBX1_K2@Z) referenced in function TL2cgenDMatrixCreateFromMat [C:\Users\mcshr\OneDrive\Everything\Mod12\TreePool\tl2cgen\build\tl2cgen.vcxproj]

  c_api.obj : error LNK2019: unresolved external symbol "public: static class std::unique_ptr<class tl2cgen::CSRDMatrix,struct std::default_delete<class tl2cgen::CSRDMatrix> > __cdecl tl2cgen::CSRDMatrix::Create(enum tl2
cgen::predictor::DataTypeEnum,void const *,unsigned int const *,unsigned __int64 const *,unsigned __int64,unsigned __int64)" (?Create@CSRDMatrix@tl2cgen@@SA?AV?$unique_ptr@VCSRDMatrix@tl2cgen@@U?$default_delete@VCSRDMatr
ix@tl2cgen@@@std@@@std@@W4DataTypeEnum@predictor@2@PEBXPEBIPEB_K_K4@Z) referenced in function TL2cgenDMatrixCreateFromCSR [C:\Users\mcshr\OneDrive\Everything\Mod12\TreePool\tl2cgen\build\tl2cgen.vcxproj]

  C:\Users\mcshr\OneDrive\Everything\Mod12\TreePool\tl2cgen\build\tl2cgen.dll : fatal error LNK1120: 2 unresolved externals [C:\Users\mcshr\OneDrive\Everything\Mod12\TreePool\tl2cgen\build\tl2cgen.vcxproj]