custom_tpool.h
#include <tl2cgen/data_matrix.h>
#include <tl2cgen/detail/threading_utils/custom_tpool/safe_queue.h>
#include <tl2cgen/detail/threading_utils/custom_tpool/spsc_queue.h>
#include <tl2cgen/detail/threading_utils/omp_config.h>
#include <tl2cgen/detail/threading_utils/parallel_for.h>
#include <tl2cgen/logging.h>
#include <tl2cgen/predictor.h>

#include <chrono>
#include <condition_variable>
#include <cstddef>
#include <functional>
#include <iostream>
#include <memory>
#include <mutex>
#include <queue>
#include <random>
#include <thread>
#include <vector>
// using namespace std;

namespace tl2cgen::detail::threading_utils::custom_tpool {
/*
idea: each thread will have its own local task queue and will be able to pop off multiple tasks from
the global queue to reduce locking contention. idea: allow for task stealing

*/
class ThreadPool {


   typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<std::function<void()>>
   spscq;

   public:
    void do_work(size_t thread_id) {
      std::function<void()> task;
      while (true) {
        task_queues_[thread_id].pop(task);
        task();

       if (stop_flags_[thread_id].load(std::memory_order_relaxed)
           || task_queues_[thread_id].empty()) {
         return;
       }
     }
     // stop_flags_[thread_id].store(true, std::memory_order_relaxed);
   }
   ThreadPool(int num_threads)
       : num_worker_(num_threads),
         workers_(num_threads),
         task_queues_(num_threads),
         stop_flags_(num_threads) {
     for (int thread_id = 0; thread_id < num_threads; ++thread_id) {
       stop_flags_[thread_id].store(false, std::memory_order_relaxed);
       workers_[thread_id] = std::thread(&ThreadPool::do_work, this, thread_id);
     }
   }
   template <typename Task>
   void submit_task(int thread_id, Task task) {
     task_queues_[thread_id].push(task);
   }

   ~ThreadPool() {
     for (int i = 0; i < num_worker_; ++i) {
       stop_flags_[i].store(true, std::memory_order_relaxed);
       workers_[i].join();
     }
   }

   private:
    alignas(std::hardware_destructive_interference_size) std::vector<std::atomic<bool>>
    stop_flags_; int num_worker_; std::vector<std::thread> workers_; std::vector<spscq>
    task_queues_; bool stop{false};
};

template <typename IndexType, typename MatType, typename FuncType>
inline void Custom_ParallelFor_ThreadPool(IndexType begin, IndexType end, MatType const* dmat,
    std::vector<std::size_t> const& row_ptr, tl2cgen::predictor::OutputBuffer* out_result,
    FuncType pred_func) {
  ThreadPool tp(end);

  for (IndexType i = begin; i < end; ++i) {
    IndexType thread_id = i;

    std::function<void()> func = [&, thread_id, dmat, out_result, pred_func]() {
      std::size_t rbegin = row_ptr[thread_id];
      std::size_t rend = row_ptr[thread_id + 1];

      pred_func(thread_id, rbegin, rend, out_result);
    };
    tp.submit_task(thread_id,func);
  }
  // printf("Main Thread DONE\n");
}

}  // namespace tl2cgen::detail::threading_utils::custom_tpool

//  for (IndexType i = begin; i < end; ++i) {
//  IndexType thread_id = i;
//  std::size_t rbegin = row_ptr[thread_id];
//  std::size_t rend = row_ptr[thread_id + 1];
//  printf("tid: %d %d %d\n", thread_id, rbegin, rend);
//
//  for (IndexType k = row_ptr[thread_id]; k < row_ptr[thread_id + 1]; ++k) {
//    printf("tid(inner): %d %d %d\n", thread_id, k, k + 1);
//    std::function<void()> func = [&, thread_id, k, out_result, pred_func]() {
//      pred_func(thread_id, k, k + 1, out_result);
//    };
//    tp.submit_task(thread_id, func);
//  }
//}
predictor.cc
/*!
 * Copyright (c) 2023 by Contributors
 * \file predictor.cc
 * \author Hyunsu Cho
 * \brief Load prediction function exported as a shared library
 */

#include <tl2cgen/data_matrix.h>
#include <tl2cgen/detail/threading_utils/custom_tpool/custom_tpool.h>
// #include <tl2cgen/detail/threading_utils/custom_tpool/spsc_queue.h>

#include <tl2cgen/detail/threading_utils/omp_config.h>
#include <tl2cgen/detail/threading_utils/parallel_for.h>
#include <tl2cgen/logging.h>
#include <tl2cgen/predictor.h>

#include <chrono>
#include <cstddef>
#include <iostream>
#include <memory>
using namespace std;
namespace {

inline double GetTime() {
  return std::chrono::duration<double>(std::chrono::high_resolution_clock::now().time_since_epoch())
      .count();
}
// Where is "create batch" function?

// Split batch function takes in input
inline std::vector<std::size_t> SplitBatch(tl2cgen::DMatrix const* dmat, std::size_t split_factor) {
  std::size_t const num_row = dmat->GetNumRow();
  TL2CGEN_CHECK_LE(split_factor, num_row);
  std::size_t const portion = num_row / split_factor;
  std::size_t const remainder = num_row % split_factor;
  std::vector<std::size_t> workload(split_factor, portion);
  std::vector<std::size_t> row_ptr(split_factor + 1, 0);

  for (std::size_t i = 0; i < remainder; ++i) {
    ++workload[i];
  }

  std::size_t accum = 0;

  for (std::size_t i = 0; i < split_factor; ++i) {
    accum += workload[i];
    row_ptr[i + 1] = accum;
  }

  return row_ptr;
}

}  // anonymous namespace

namespace tl2cgen::predictor {

// Builds prediction function
Predictor::Predictor(char const* libpath, int num_worker_thread) {
  // printf("NUM_WORKER_THREADs %d\n", num_worker_thread); // 20
  thread_config_ = tl2cgen::detail::threading_utils::ConfigureThreadConfig(num_worker_thread);
  lib_ = std::make_unique<detail::SharedLibrary>(libpath);
  using UnsignedQueryFunc = std::size_t (*)();
  using StringQueryFunc = char const* (*)();
  using FloatQueryFunc = float (*)();

  /* 1. query # of output groups */
  auto* num_class_query_func = lib_->LoadFunctionWithSignature<UnsignedQueryFunc>("get_num_class");
  num_class_ = num_class_query_func();

  /* 2. query # of features */
  auto* num_feature_query_func
      = lib_->LoadFunctionWithSignature<UnsignedQueryFunc>("get_num_feature");
  num_feature_ = num_feature_query_func();
  TL2CGEN_CHECK_GT(num_feature_, 0) << "num_feature cannot be zero";

  /* 3. query # of pred_transform name */
  auto* pred_transform_query_func
      = lib_->LoadFunctionWithSignature<StringQueryFunc>("get_pred_transform");
  pred_transform_ = pred_transform_query_func();

  /* 4. query # of sigmoid_alpha */
  auto* sigmoid_alpha_query_func
      = lib_->LoadFunctionWithSignature<FloatQueryFunc>("get_sigmoid_alpha");
  sigmoid_alpha_ = sigmoid_alpha_query_func();

  /* 5. query # of ratio_c */
  auto* ratio_c_query_func = lib_->LoadFunctionWithSignature<FloatQueryFunc>("get_ratio_c");
  ratio_c_ = ratio_c_query_func();

  /* 6. query # of global_bias */
  auto* global_bias_query_func = lib_->LoadFunctionWithSignature<FloatQueryFunc>("get_global_bias");
  global_bias_ = global_bias_query_func();

  /* 7. Query the data type for thresholds and leaf outputs */
  auto* threshold_type_query_func
      = lib_->LoadFunctionWithSignature<StringQueryFunc>("get_threshold_type");
  threshold_type_ = threshold_type_query_func();
  auto* leaf_output_type_query_func
      = lib_->LoadFunctionWithSignature<StringQueryFunc>("get_leaf_output_type");
  leaf_output_type_ = leaf_output_type_query_func();

  /* 8. load appropriate function for margin prediction */
  TL2CGEN_CHECK_GT(num_class_, 0) << "num_class cannot be zero";
  pred_func_ = std::make_unique<PredictFunction>(DataTypeFromString(threshold_type_),
      DataTypeFromString(leaf_output_type_), *lib_, static_cast<int>(num_feature_),
      static_cast<int>(num_class_));
}

struct InputToken {
  DMatrix const* dmat;
  bool pred_margin;
  size_t rbegin, rend;
  tl2cgen::predictor::PredictFunction const* pred_func_;
  OutputBuffer* out_result;
  size_t id;
};
struct OutputToken {
  size_t result_size;
};

std::size_t Predictor::PredictBatch(
    DMatrix const* dmat, int verbose, bool pred_margin, OutputBuffer* out_result) const {
  std::size_t const num_row = dmat->GetNumRow();
  if (num_row == 0) {
    return 0;
  }
  double const tstart = GetTime();
  std::size_t const nthread = std::min(static_cast<std::size_t>(thread_config_.nthread), num_row);

  std::vector<std::size_t> const row_ptr = SplitBatch(dmat, nthread);  // Split batch
  std::size_t total_size = 0;
  std::vector<std::size_t> result_size(nthread);

  //typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<InputToken>* spscq_in;
  //typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<OutputToken>* spscq_out;
  //using ThreadPool_
  //    = tl2cgen::detail::threading_utils::custom_tpool::ThreadPool<InputToken, OutputToken>;
  //// CUSTOM BEGIN

  //ThreadPool_ tp(nthread, [this](spscq_in in_queue, spscq_out out_queue) {
  //  exception_catcher_.Run([&]() {
  //    InputToken input;
  //    while (in_queue->pop(&input)) {
  //      printf("popped %d\n",input.id);
  //      const size_t rbegin = input.rbegin;
  //      const size_t rend = input.rend;
  //      size_t result_size = pred_func_->PredictBatch(
  //          input.dmat, rbegin, rend, input.pred_margin, input.out_result);
  //      out_queue->push(OutputToken{result_size});
  //    }
  //  });
  //});


  //InputToken request{dmat, pred_margin, 0, num_row, pred_func_.get(), out_result,-1};
  //OutputToken response;
  //for (size_t thread_id = 0; thread_id < nthread; ++thread_id) {
  //  request.rbegin = row_ptr[thread_id];
  //  request.rend = row_ptr[thread_id + 1];
  //  request.id = thread_id;
  //  tp.submit_task(thread_id, request);
  //}

  //{
  //  size_t const rbegin = row_ptr[nthread - 1];
  //  size_t const rend = row_ptr[nthread];
  //  size_t const query_result_size
  //      = pred_func_->PredictBatch(dmat, rbegin, rend, pred_margin, out_result);
  //  total_size += query_result_size;
  //}

 /* for (size_t thread_id = 0; thread_id < nthread; ++thread_id) {
    if (tp.wait_for_task(thread_id, &response)) {
      total_size += response.result_size;
    }
  }*/

  // printf("RES %d\n", total_size);

   tl2cgen::detail::threading_utils::custom_tpool::Custom_ParallelFor_ThreadPool(std::size_t(0),
       nthread, dmat, row_ptr, out_result,
      [&](std::size_t thread_id, std::size_t rbegin, std::size_t rend, OutputBuffer* out_result)
       {
        result_size[thread_id]
            = pred_func_->PredictBatch(dmat, rbegin, rend, pred_margin, out_result);
      });

  // CUSTOM END

  // tl2cgen::detail::threading_utils::ParallelFor(std::size_t(0), nthread, thread_config_,
  // tl2cgen::detail::threading_utils::ParallelSchedule::Static(),

  //    [&](std::size_t thread_id, int x) { //what is this int? => int val is just the thread_id??

  //      std::size_t rbegin = row_ptr[thread_id];

  //      std::size_t rend = row_ptr[thread_id + 1];

  //      result_size[thread_id] = pred_func_->PredictBatch(dmat, rbegin, rend, pred_margin,
  //      out_result);
  //      //printf("X %d TID %d \n", x,thread_id);
  //      //cout << "thread ID " << thread_id << " end \n";
  //      //cout << "begin " << rbegin << " end \n";
  //      //cout << "end " << rend << " end \n";
  //    }); // This lambda expression is whats being paralellized

   for (auto e : result_size) {
     total_size += e;
   }
  //  Re-shape output if total_size < dimension of out_result
  if (total_size < QueryResultSize(dmat, 0, num_row)) {
    TL2CGEN_CHECK_GT(num_class_, 1);

    TL2CGEN_CHECK_EQ(total_size % num_row, 0);

    std::size_t const query_size_per_instance = total_size / num_row;

    TL2CGEN_CHECK_GT(query_size_per_instance, 0);

    TL2CGEN_CHECK_LT(query_size_per_instance, num_class_);
    std::visit(
        [&, num_class = num_class_](auto&& pred_func_concrete, auto&& out_pred_ptr) {
          using LeafOutputType =
              typename std::remove_reference_t<decltype(pred_func_concrete)>::leaf_output_type;

          using ExpectedLeafOutputType
              = std::remove_pointer_t<std::remove_reference_t<decltype(out_pred_ptr)>>;

          if constexpr (std::is_same_v<LeafOutputType, ExpectedLeafOutputType>) {
            auto* out_result_ = static_cast<LeafOutputType*>(out_result->data());

            for (std::size_t rid = 0; rid < num_row; ++rid) {
              for (std::size_t k = 0; k < query_size_per_instance; ++k) {
                out_result_[rid * query_size_per_instance + k] = out_result_[rid * num_class + k];
              }
            }
          } else {
            TL2CGEN_LOG(FATAL)
                << "Type mismatch between LeafOutputType of the model and the output buffer. "
                << "LeafOutputType = " << typeid(LeafOutputType).name()
                << ", ExpectedLeafOutputType = " << typeid(ExpectedLeafOutputType).name();
          }
        },
        pred_func_->variant_, out_result->variant_);
  }
  double const tend = GetTime();
  if (verbose > 0) {
    TL2CGEN_LOG(INFO) << "TL2cgen: Finished prediction in " << (tend - tstart) << " sec";

  }
  return total_size;
}

}  // namespace tl2cgen::predictor

spsc_queue.h

#include <tl2cgen/detail/threading_utils/custom_tpool/spinlock.h>

#include <atomic>
#include <condition_variable>
#include <mutex>
#include <queue>
#include <thread>
#include <vector>
namespace tl2cgen::detail::threading_utils::custom_tpool {

constexpr int const kL1CacheBytes = 64;
template <typename T>
class SPSC_Queue {
  // typedef tl2cgen::detail::threading_utils::custom_tpool::SpinLock Spinlock;

 public:
  SPSC_Queue()
      : head_(0), tail_(0), stop_(false), capacity_(max_size), buffer_(max_size) {}

  ~SPSC_Queue() = default;

  size_t incr(size_t x) {
    return (x + 1) % capacity_;
  }


  bool push(T& item) {
    std::unique_lock<Spinlock> lock(spinlock);
    size_t const current_tail = tail_.load(std::memory_order_relaxed);

    if ((current_tail + 1) % capacity_ != head_.load(std::memory_order_acquire)) {
      buffer_[current_tail] = item;
      tail_.store((current_tail + 1) % capacity_, std::memory_order_release);
      //printf("pushing: %d\n", size());
      lock.unlock();
      condition_.notify_one();
      return true;
    }
    // printf("Failed to push\n");
    lock.unlock();
    return false;
  }
  // must maintain 1 empty slot between head and tail since otherwise head = tail => queue is empty,
  // but its full.
  bool pop(T& item) {
    std::unique_lock<Spinlock> lock(spinlock);
    condition_.wait(lock, [this] { return !empty(); });
    size_t const current_head = head_.load(std::memory_order_relaxed);
    if (current_head == tail_.load(std::memory_order_acquire)) {
      // printf("failed to pop\n");
      lock.unlock();
      return false;
    }
    item = buffer_[current_head];
    head_.store((current_head + 1) % capacity_, std::memory_order_release);
    // printf("popped\n");
    lock.unlock();
    return true;
  }
  size_t size() {
    return tail_.load(std::memory_order_relaxed) - head_.load(std::memory_order_relaxed);
  }
  bool full() {
    size_t current_tail = tail_.load(std::memory_order_relaxed);
    size_t next_tail = incr(current_tail);
    return (next_tail == head_.load(std::memory_order_relaxed));
  }

  bool empty() {
    return tail_.load(std::memory_order_relaxed) == head_.load(std::memory_order_relaxed);
  }
  bool do_stop() {
    return stop_.load();
  }

 private:
  // typedef char cache_line_pad_t[kL1CacheBytes];
  // cache_line_pad_t pad0_;
  static constexpr int const max_size = 2;
  std::vector<T> buffer_;

  // cache_line_pad_t pad1_;
  alignas(std::hardware_destructive_interference_size) std::atomic<size_t> head_;

  // cache_line_pad_t pad2_;
  alignas(std::hardware_destructive_interference_size) std::atomic<size_t> tail_;

  // cache_line_pad_t pad3_;
  alignas(std::hardware_destructive_interference_size) std::atomic<bool> stop_;

  // cache_line_pad_t pad4_;
  char padding_[std::hardware_destructive_interference_size - sizeof(std::size_t)];

  Spinlock spinlock;

  size_t const capacity_;
  std::mutex mutex_;
  std::condition_variable_any condition_;
  // std::atomic<size_t> size_;
};

}  // namespace tl2cgen::detail::threading_utils::custom_tpool