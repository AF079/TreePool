custom_tpool.h

#include <tl2cgen/data_matrix.h>
#include <tl2cgen/detail/threading_utils/custom_tpool/safe_queue.h>
#include <tl2cgen/detail/threading_utils/custom_tpool/spsc_queue.h>
#include <tl2cgen/detail/threading_utils/omp_config.h>
#include <tl2cgen/detail/threading_utils/parallel_for.h>
#include <tl2cgen/logging.h>
#include <tl2cgen/predictor.h>

#include <chrono>
#include <condition_variable>
#include <cstddef>
#include <functional>
#include <iostream>
#include <memory>
#include <mutex>
#include <queue>
#include <random>
#include <thread>
#include <vector>

// using namespace std;

namespace tl2cgen::detail::threading_utils::custom_tpool {
/*
idea: each thread will have its own local task queue and will be able to pop off multiple tasks from
the global queue to reduce locking contention. idea: allow for task stealing

*/

struct InputToken {
  tl2cgen::DMatrix const* dmat;
  std::size_t rbegin;
  std::size_t rend;
  bool pred_margin;
  tl2cgen::predictor::OutputBuffer* out_result;
  tl2cgen::predictor::PredictFunction const* pred_func_;
};

struct OutputToken {
  size_t result_size;
};

class ThreadPool {
  typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<InputToken> spscq_in;
  typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<OutputToken> spscq_out;

 public:
  void do_work(size_t thread_id) {
    InputToken token;
    while (in_queue_[thread_id]->pop(&token)) {
      printf("tid %d\n", thread_id);
      printf("popped\n");
      size_t result_size = token.pred_func_->PredictBatch(
          token.dmat, token.rbegin, token.rend, token.pred_margin, token.out_result);
      out_queue_[thread_id]->push(OutputToken{result_size});
      // if (in_queue_[thread_id]->pop(&token)) {

      /*  if (stop_flags_[thread_id].load(std::memory_order_relaxed)
            || in_queue_[thread_id]->empty()) {
          return;
        }*/
      //}
      // task();
    }
    // stop_flags_[thread_id].store(true, std::memory_order_relaxed);
  }
  ThreadPool(int num_threads, std::size_t& total_size)
      : num_worker_(num_threads),
        workers_(num_threads),
        in_queue_(num_threads),
        out_queue_(num_threads),
        stop_flags_(num_threads) {
    for (int thread_id = 0; thread_id < num_threads; ++thread_id) {
      stop_flags_[thread_id].store(false, std::memory_order_relaxed);
      workers_[thread_id] = std::thread(&ThreadPool::do_work, this, thread_id);
    }
  }
  void submit_task(int thread_id, InputToken task) {
    printf("pushing for tid %d\n", thread_id);
    in_queue_[thread_id]->push(task);
  }

  void compute_total(std::size_t& total_size) {
    OutputToken response;
    for (std::size_t i = 0; i < num_worker_; ++i) {
      if (out_queue_[i]->pop(&response)) {
        total_size += response.result_size;
      }
    }
  }

  ~ThreadPool() {
    for (int i = 0; i < num_worker_; ++i) {
      in_queue_[i]->SignalForKill();
      out_queue_[i]->SignalForKill();
      workers_[i].join();
    }
  }

 private:
  alignas(std::hardware_destructive_interference_size) std::vector<std::atomic<bool>> stop_flags_;
  int num_worker_;
  std::vector<std::thread> workers_;
  std::vector<std::unique_ptr<spscq_in>> in_queue_;
  std::vector<std::unique_ptr<spscq_out>> out_queue_;

  bool stop{false};
};

inline void Custom_ParallelFor_ThreadPool(std::size_t begin, std::size_t end,
    tl2cgen::DMatrix const* dmat, std::vector<std::size_t> const& row_ptr, bool pred_margin,
    tl2cgen::predictor::OutputBuffer* out_result,
    tl2cgen::predictor::PredictFunction const* pred_func_, std::size_t& total_size) {
  ThreadPool tp(end, total_size);

  std::size_t const num_row = dmat->GetNumRow();

  InputToken token{dmat, -1, -1, pred_margin, out_result, pred_func_};
  for (std::size_t i = begin; i < end; ++i) {
    /*std::size_t rbegin = row_ptr[i];
    std::size_t rend = row_ptr[i + 1];*/
    token.rbegin = row_ptr[i];
    token.rend = row_ptr[i + 1];
    /*std::function<void()> func = [&, i, out_result, pred_func_]() {
      std::size_t rbegin = row_ptr[i];
      std::size_t rend = row_ptr[i + 1];

      pred_func_(i, rbegin, rend, out_result);
    };*/
    tp.submit_task(i, token);
  }
  tp.compute_total(total_size);
}

}  // namespace tl2cgen::detail::threading_utils::custom_tpool


predictor.cc

/*!
 * Copyright (c) 2023 by Contributors
 * \file predictor.cc
 * \author Hyunsu Cho
 * \brief Load prediction function exported as a shared library
 */

#include <tl2cgen/data_matrix.h>
#include <tl2cgen/detail/threading_utils/custom_tpool/custom_tpool.h>
// #include <tl2cgen/detail/threading_utils/custom_tpool/spsc_queue.h>

#include <tl2cgen/detail/threading_utils/omp_config.h>
#include <tl2cgen/detail/threading_utils/parallel_for.h>
#include <tl2cgen/logging.h>
#include <tl2cgen/predictor.h>

#include <chrono>
#include <cstddef>
#include <iostream>
#include <memory>
using namespace std;
namespace {

inline double GetTime() {
  return std::chrono::duration<double>(std::chrono::high_resolution_clock::now().time_since_epoch())
      .count();
}
// Where is "create batch" function?

// Split batch function takes in input
inline std::vector<std::size_t> SplitBatch(tl2cgen::DMatrix const* dmat, std::size_t split_factor) {
  std::size_t const num_row = dmat->GetNumRow();
  TL2CGEN_CHECK_LE(split_factor, num_row);
  std::size_t const portion = num_row / split_factor;
  std::size_t const remainder = num_row % split_factor;
  std::vector<std::size_t> workload(split_factor, portion);
  std::vector<std::size_t> row_ptr(split_factor + 1, 0);

  for (std::size_t i = 0; i < remainder; ++i) {
    ++workload[i];
  }

  std::size_t accum = 0;

  for (std::size_t i = 0; i < split_factor; ++i) {
    accum += workload[i];
    row_ptr[i + 1] = accum;
  }

  return row_ptr;
}

}  // anonymous namespace

namespace tl2cgen::predictor {

// Builds prediction function
Predictor::Predictor(char const* libpath, int num_worker_thread) {
  // printf("NUM_WORKER_THREADs %d\n", num_worker_thread); // 20
  thread_config_ = tl2cgen::detail::threading_utils::ConfigureThreadConfig(num_worker_thread);
  lib_ = std::make_unique<detail::SharedLibrary>(libpath);
  using UnsignedQueryFunc = std::size_t (*)();
  using StringQueryFunc = char const* (*)();
  using FloatQueryFunc = float (*)();

  /* 1. query # of output groups */
  auto* num_class_query_func = lib_->LoadFunctionWithSignature<UnsignedQueryFunc>("get_num_class");
  num_class_ = num_class_query_func();

  /* 2. query # of features */
  auto* num_feature_query_func
      = lib_->LoadFunctionWithSignature<UnsignedQueryFunc>("get_num_feature");
  num_feature_ = num_feature_query_func();
  TL2CGEN_CHECK_GT(num_feature_, 0) << "num_feature cannot be zero";

  /* 3. query # of pred_transform name */
  auto* pred_transform_query_func
      = lib_->LoadFunctionWithSignature<StringQueryFunc>("get_pred_transform");
  pred_transform_ = pred_transform_query_func();

  /* 4. query # of sigmoid_alpha */
  auto* sigmoid_alpha_query_func
      = lib_->LoadFunctionWithSignature<FloatQueryFunc>("get_sigmoid_alpha");
  sigmoid_alpha_ = sigmoid_alpha_query_func();

  /* 5. query # of ratio_c */
  auto* ratio_c_query_func = lib_->LoadFunctionWithSignature<FloatQueryFunc>("get_ratio_c");
  ratio_c_ = ratio_c_query_func();

  /* 6. query # of global_bias */
  auto* global_bias_query_func = lib_->LoadFunctionWithSignature<FloatQueryFunc>("get_global_bias");
  global_bias_ = global_bias_query_func();

  /* 7. Query the data type for thresholds and leaf outputs */
  auto* threshold_type_query_func
      = lib_->LoadFunctionWithSignature<StringQueryFunc>("get_threshold_type");
  threshold_type_ = threshold_type_query_func();
  auto* leaf_output_type_query_func
      = lib_->LoadFunctionWithSignature<StringQueryFunc>("get_leaf_output_type");
  leaf_output_type_ = leaf_output_type_query_func();

  /* 8. load appropriate function for margin prediction */
  TL2CGEN_CHECK_GT(num_class_, 0) << "num_class cannot be zero";
  pred_func_ = std::make_unique<PredictFunction>(DataTypeFromString(threshold_type_),
      DataTypeFromString(leaf_output_type_), *lib_, static_cast<int>(num_feature_),
      static_cast<int>(num_class_));
}

struct InputToken {
  DMatrix const* dmat;
  bool pred_margin;
  size_t rbegin, rend;
  tl2cgen::predictor::PredictFunction const* pred_func_;
  OutputBuffer* out_result;
  size_t id;
};
struct OutputToken {
  size_t result_size;
};

std::size_t Predictor::PredictBatch(
    DMatrix const* dmat, int verbose, bool pred_margin, OutputBuffer* out_result) const {
  std::size_t const num_row = dmat->GetNumRow();
  if (num_row == 0) {
    return 0;
  }
  double const tstart = GetTime();
  std::size_t const nthread = std::min(static_cast<std::size_t>(thread_config_.nthread), num_row);

  std::vector<std::size_t> const row_ptr = SplitBatch(dmat, nthread);  // Split batch
  std::size_t total_size = 0;
  std::vector<std::size_t> result_size(nthread);

  // typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<InputToken>* spscq_in;
  // typedef tl2cgen::detail::threading_utils::custom_tpool::SPSC_Queue<OutputToken>* spscq_out;
  // using ThreadPool_
  //     = tl2cgen::detail::threading_utils::custom_tpool::ThreadPool<InputToken, OutputToken>;
  //// CUSTOM BEGIN

  // ThreadPool_ tp(nthread, [this](spscq_in in_queue, spscq_out out_queue) {
  //   exception_catcher_.Run([&]() {
  //     InputToken input;
  //     while (in_queue->pop(&input)) {
  //       printf("popped %d\n",input.id);
  //       const size_t rbegin = input.rbegin;
  //       const size_t rend = input.rend;
  //       size_t result_size = pred_func_->PredictBatch(
  //           input.dmat, rbegin, rend, input.pred_margin, input.out_result);
  //       out_queue->push(OutputToken{result_size});
  //     }
  //   });
  // });

  // InputToken request{dmat, pred_margin, 0, num_row, pred_func_.get(), out_result,-1};
  // OutputToken response;
  // for (size_t thread_id = 0; thread_id < nthread; ++thread_id) {
  //   request.rbegin = row_ptr[thread_id];
  //   request.rend = row_ptr[thread_id + 1];
  //   request.id = thread_id;
  //   tp.submit_task(thread_id, request);
  // }

  //{
  //  size_t const rbegin = row_ptr[nthread - 1];
  //  size_t const rend = row_ptr[nthread];
  //  size_t const query_result_size
  //      = pred_func_->PredictBatch(dmat, rbegin, rend, pred_margin, out_result);
  //  total_size += query_result_size;
  //}

  /* for (size_t thread_id = 0; thread_id < nthread; ++thread_id) {
     if (tp.wait_for_task(thread_id, &response)) {
       total_size += response.result_size;
     }
   }*/

  // printf("RES %d\n", total_size);
  
  tl2cgen::detail::threading_utils::custom_tpool::Custom_ParallelFor_ThreadPool(std::size_t(0),
      nthread, dmat, row_ptr, pred_margin,out_result,pred_func_.get(), total_size);
  //[&](std::size_t thread_id, std::size_t rbegin, std::size_t rend, OutputBuffer* out_result) {
  //  result_size[thread_id] += pred_func_->PredictBatch(dmat, rbegin, rend, pred_margin, out_result);
  //  // total_size += result_size[thread_id];
  //}
  // CUSTOM END

  // tl2cgen::detail::threading_utils::ParallelFor(std::size_t(0), nthread, thread_config_,
  // tl2cgen::detail::threading_utils::ParallelSchedule::Static(),

  //    [&](std::size_t thread_id, int x) { //what is this int? => int val is just the thread_id??

  //      std::size_t rbegin = row_ptr[thread_id];

  //      std::size_t rend = row_ptr[thread_id + 1];

  //      result_size[thread_id] = pred_func_->PredictBatch(dmat, rbegin, rend, pred_margin,
  //      out_result);
  //      //printf("X %d TID %d \n", x,thread_id);
  //      //cout << "thread ID " << thread_id << " end \n";
  //      //cout << "begin " << rbegin << " end \n";
  //      //cout << "end " << rend << " end \n";
  //    }); // This lambda expression is whats being paralellized
  tl2cgen::detail::threading_utils::custom_tpool::Custom_ParallelFor_ThreadPool(std::size_t(0),
      nthread, dmat, row_ptr, pred_margin,out_result,pred_func_.get(), total_size);
  for (auto e : result_size) {
    total_size += e;
  }
  printf("%d\n", total_size);
  //  Re-shape output if total_size < dimension of out_result
  if (total_size < QueryResultSize(dmat, 0, num_row)) {
    TL2CGEN_CHECK_GT(num_class_, 1);

    TL2CGEN_CHECK_EQ(total_size % num_row, 0);

    std::size_t const query_size_per_instance = total_size / num_row;

    TL2CGEN_CHECK_GT(query_size_per_instance, 0);

    TL2CGEN_CHECK_LT(query_size_per_instance, num_class_);
    std::visit(
        [&, num_class = num_class_](auto&& pred_func_concrete, auto&& out_pred_ptr) {
          using LeafOutputType =
              typename std::remove_reference_t<decltype(pred_func_concrete)>::leaf_output_type;

          using ExpectedLeafOutputType
              = std::remove_pointer_t<std::remove_reference_t<decltype(out_pred_ptr)>>;

          if constexpr (std::is_same_v<LeafOutputType, ExpectedLeafOutputType>) {
            auto* out_result_ = static_cast<LeafOutputType*>(out_result->data());

            for (std::size_t rid = 0; rid < num_row; ++rid) {
              for (std::size_t k = 0; k < query_size_per_instance; ++k) {
                out_result_[rid * query_size_per_instance + k] = out_result_[rid * num_class + k];
              }
            }
          } else {
            TL2CGEN_LOG(FATAL)
                << "Type mismatch between LeafOutputType of the model and the output buffer. "
                << "LeafOutputType = " << typeid(LeafOutputType).name()
                << ", ExpectedLeafOutputType = " << typeid(ExpectedLeafOutputType).name();
          }
        },
        pred_func_->variant_, out_result->variant_);
  }
  double const tend = GetTime();
  if (verbose > 0) {
    TL2CGEN_LOG(INFO) << "TL2cgen: Finished in " << (tend - tstart) << " sec";
  }
  return total_size;
}

}  // namespace tl2cgen::predictor


spsc_queue.h

#include <tl2cgen/detail/threading_utils/custom_tpool/spinlock.h>

#include <atomic>
#include <condition_variable>
#include <mutex>
#include <queue>
#include <thread>
#include <vector>

namespace tl2cgen::detail::threading_utils::custom_tpool {

constexpr int const kL1CacheBytes = 64;
template <typename T>
class SPSC_Queue {
  // typedef tl2cgen::detail::threading_utils::custom_tpool::SpinLock Spinlock;

 public:
  SPSC_Queue() : head_(0), tail_(0), stop_(false), capacity_(max_size), buffer_(new T[max_size]) {}

  ~SPSC_Queue() {
    delete[] buffer_;
  }

  size_t incr(size_t x) {
    return (x + 1) % capacity_;
  }

  void push(T const& item) {
    while (!enqueue(item)) {
      std::this_thread::yield();
    }
    if (pending_.fetch_add(1) == -1) {
      std::unique_lock<std::mutex> lock(mutex_);
      condition_.notify_one();
    }
    //std::unique_lock<std::mutex> lock(mutex_);
    //condition_.notify_one();
  }
  void SignalForKill() {
    std::lock_guard<std::mutex> lock(mutex_);
    stop_.store(true);
    condition_.notify_all();
  }
  bool enqueue(T const& item) {
    printf("pushing\n");
    // std::unique_lock<Spinlock> lock(spinlock);

    
    size_t const current_tail = tail_.load(std::memory_order_relaxed);

    if ((current_tail + 1) % capacity_ != head_.load(std::memory_order_acquire)) {
      buffer_[current_tail] = item;
      tail_.store((current_tail + 1) % capacity_, std::memory_order_release);
      // printf("pushing: %d\n", size());
      // lock.unlock();
      // condition_.notify_one();
      return true;
    }
    // printf("Failed to push\n");
    return false;
  }
  // must maintain 1 empty slot between head and tail since otherwise head = tail => queue is empty,
  // but its full.
  bool pop(T* item) {
    printf("trying to pop\n");
    //std::unique_lock<std::mutex> lock(mutex_);
    //condition_.wait(lock, [this] { return !empty(); });
    //printf("size: %d\n", size());
    for (uint32_t i = 0; i < 300000 && pending_.load() == 0; ++i) {
      std::this_thread::yield();
    }
    if (pending_.fetch_sub(1) == 0) {
      std::unique_lock<std::mutex> lock(mutex_);
      condition_.wait(lock, [this] { return pending_.load() >= 0 || stop_.load(); });
    }
    if (stop_.load(std::memory_order_relaxed)) {
      return false;
    }
    size_t const current_head = head_.load(std::memory_order_relaxed);
    if (current_head == tail_.load(std::memory_order_acquire)) {
      // printf("failed to pop\n");
      // lock.unlock();
      return false;
    }
    *item = buffer_[current_head];
    head_.store((current_head + 1) % capacity_, std::memory_order_release);
    // printf("popped\n");
    // lock.unlock();
    return true;
  }
  size_t size() {
    return tail_.load(std::memory_order_relaxed) - head_.load(std::memory_order_relaxed);
  }
  bool full() {
    size_t current_tail = tail_.load(std::memory_order_relaxed);
    size_t next_tail = incr(current_tail);
    return (next_tail == head_.load(std::memory_order_relaxed));
  }

  bool empty() {
    printf("HERE??\n");
    return tail_.load(std::memory_order_relaxed) == head_.load(std::memory_order_relaxed);
  }
  bool do_stop() {
    return stop_.load();
  }

 private:
  // typedef char cache_line_pad_t[kL1CacheBytes];
  // cache_line_pad_t pad0_;
  static constexpr int const max_size = 2;
  // std::vector<T> buffer_;
  T* const buffer_;
  // cache_line_pad_t pad1_;
  alignas(std::hardware_destructive_interference_size) std::atomic<size_t> head_;

  // cache_line_pad_t pad2_;
  alignas(std::hardware_destructive_interference_size) std::atomic<size_t> tail_;

  // cache_line_pad_t pad3_;
  alignas(std::hardware_destructive_interference_size) std::atomic<bool> stop_;
  std::atomic<int8_t> pending_{0};
  // cache_line_pad_t pad4_;
  char padding_[std::hardware_destructive_interference_size - sizeof(std::size_t)];

  Spinlock spinlock;

  size_t const capacity_;
  std::mutex mutex_;
  std::condition_variable_any condition_;
  // std::atomic<size_t> size_;
};

}  // namespace tl2cgen::detail::threading_utils::custom_tpool